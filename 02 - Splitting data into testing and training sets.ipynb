{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Splitting data into testing and training sets\n",
    "___\n",
    "\n",
    "Step 2! We have downloaded and joined the data for Casualties and Collisions over the last 5 years. Let's now split our data up into testing and training so that we don't peek at our testing data as this should be treated as completely unseen data.\n",
    "\n",
    "There are a couple of key things to think about here:\n",
    "  1. There may be multiple entries for each accident_index for collisions where there were multiple casulaties. We need to make sure that duplicate accident_index values are split into either the training or testing set. If the same accident is across both, then the model will have already 'seen' this accident and we will have a severe data leakage situation on our hands!\n",
    "  2. Our classification categories are really severely unbalanced. We need to stratify the data split so that we preserve the same proportion of examples of each class into the testing and training data. Down the line we could consider bootstrapping the data to synthetically increase the proportion of \"severe\" classifications, but as you can imagine this can be tricky as we will overweight the model towards the features of the bootstrapped collisions.\n",
    "  3. We only have 14,179 total data entries. On the ML-scale, this is quite a small dataset so instead of splitting the data into training, validation, and testing data, we will instead use k-fold cross-validation on the training data to use as much data as possible for model training.\n",
    "\n",
    "First, let's import our libraries and read in the data .csv that we just made.\n",
    "\n",
    "---\n",
    "\n",
    "#### Note that we will use the 'casualty_severity' column as our predictor. This is important to use instead of the accident_severity, as some multi-person collisions have a mix of slight and serious injuries. It it unfortunate that the name is still 'accident' rather than 'collision'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dft_statistics_collision_and_casualty_last_5_years.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, we can see that the classes in the dataset are really unbalanced - 73% of the collisions were slight, 26% were serious, and only 1% of the casualties were fatal.\n",
    "\n",
    "If we want to use our model to try and reduce the number of road collisions that have serious consequences, then I don't think we need to distinguish between fatal or serious collisions. Let's combine these into one 'Serious' class.\n",
    "\n",
    "This means that our classes are still unbalanced, 73% versus 27%. We need to bear this in mind when we evaluate the performance of our model, and preserve these proportions between our testing and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "casualty_severity\n",
       "Slight     73.0\n",
       "Serious    26.0\n",
       "Fatal       1.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(data.casualty_severity.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "casualty_severity\n",
       "Slight     73.0\n",
       "Serious    27.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['casualty_severity'] = data['casualty_severity'].replace('Fatal', 'Serious')\n",
    "np.round(data.casualty_severity.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's seperate our training and test data to prevent any data leakage. We need to be a little bit clever here, as accidents with multiple casualties have multiple entries. We need to make sure that the duplicate accident_index entries are not split between the train and test sets, as this would be quie a severe leakage of information.\n",
    "\n",
    "To do this, let's make a dummy dataframe with only the unique accident_indexes, randomly split between test and train as normal, and then append the duplicate crash entries to the appropriate set (train or test.)\n",
    "\n",
    "We should also be aware that we have unbalanced classes in the casualty_severity predictor, so we should stratify our split (easily done using scikit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14179 total entries in the dataset.\n",
      "There are 10688 unique accident indexes in the dataset.\n",
      "The new dataset without duplicates has 10688 unique accident indexes and 10688 total entries\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(data)} total entries in the dataset.')\n",
    "print(f'There are {data.accident_index.nunique()} unique accident indexes in the dataset.')\n",
    "\n",
    "data_no_dup = data.groupby('accident_index').first().reset_index()\n",
    "print(f'The new dataset without duplicates has {data_no_dup.accident_index.nunique()} unique accident indexes and {len(data_no_dup)} total entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just do a quick check that we've done that correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(data_no_dup.accident_index.unique() == data.accident_index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're using Scitkit-learn's test_train_split to randomly split the data from the dataset without duplicate accident_indexes into 80% training data and 20% testing data. We need to specify the random_state so that we get the exact same results every time we run this code. This is really important for reproducibility of our modelling. We are specifying the 'casualty_severity' predictor column as the column to stratify the data on. This means we will preserve the balance of the Slight vs. Serious classes.\n",
    "\n",
    "After we've split the data I'm merging the original dataset and dropping any duplicate columns that we don't need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_dup, test_no_dup = train_test_split(data_no_dup, test_size=0.2, stratify=data_no_dup['casualty_severity'], random_state=42)\n",
    "\n",
    "train = train_no_dup.merge(data, on='accident_index', how='left', suffixes=('', '_remove'))\n",
    "test = test_no_dup.merge(data, on='accident_index', how='left', suffixes=('', '_remove'))\n",
    "\n",
    "# remove the duplicate columns\n",
    "train.drop([i for i in train.columns if 'remove' in i], axis=1, inplace=True)\n",
    "test.drop([i for i in test.columns if 'remove' in i], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should make sure we're happy with the splits. Let's check we have the correct number of data entries, the correct number of unique collisions, and finally a quick test for any leakage of the accident indexes between the training and testing datasets. By inner merging on the accident_index we only keep entries that are common across the two datasets. As there aren't any then our splitting has worked well, woohoo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14179"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0] + test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10688"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.accident_index.nunique() + test.accident_index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(acc_idx in test.accident_index for acc_idx in train.accident_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "dup_check = train.merge(test, on='accident_index', how='inner')\n",
    "print(dup_check.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish, let's export the data to read in next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train.to_csv('training_data.csv', index=False)\n",
    "testing_data = test.to_csv('testing_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### We're happy with our seperated data so now let's do some data wrangling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DfT_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
